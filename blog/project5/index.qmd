# Project 5: Data Wranging for Customers Demand Estimation 

This project is showing how I did data wrangling for the mlogit package to support further researching topics in later projects. it's a boring topic and feel free to ignore it. 

## Introduction
The Multinomial Logit Model (MNL) is a predictive modeling technique often used in demand prediction when the outcome of interest has more than two categorical outcomes. It is an extension of the logistic regression model to multiple classes. This model is particularly useful in scenarios like predicting customer choice among several products, transport mode selection, or any situation where individuals select from multiple options.

How the Multinomial Logit Model Works:

	1.	Probabilistic Framework: The model estimates the probabilities of each possible outcome as a function of the independent variables.
	2.	Utility-Based: Each choice option is assumed to have a utility associated with it, which is modeled as a linear combination of explanatory variables.
	3.	Logit Function: It uses a logit function to model the probability that a particular alternative is chosen.

Applications in Demand Prediction:

	•	Transport Economics: Predicting the mode of transport (bus, train, car, etc.) a person might choose based on various factors like cost, time, and comfort.
	•	Marketing: Determining which product a consumer is likely to purchase based on features such as price, brand, and consumer demographics.
	•	Public Policy: Assessing the likelihood of individuals opting for different public services.

Data Wrangling for Multinomial Logit Model:

Data wrangling, or data preprocessing, is a crucial step before applying any predictive modeling technique. Here’s how you might go about it for the Multinomial Logit Model:

	1.	Data Cleaning:
	•	Missing Values: Handle missing data through imputation or removal.
	•	Outliers: Identify and treat outliers as they can skew the results.
	2.	Data Transformation:
	•	Normalization/Standardization: Scale numeric features to have a mean of zero 
	  and a standard deviation of one, or transform them to range between 0 and 1.
	•	Encoding Categorical Variables: Convert categorical variables into dummy/indicator 
	  variables.For instance, using one-hot encoding.
	3.	Feature Selection:
	•	Identify which features are most relevant to the prediction. This can be achieved 
	  through statistical tests, domain knowledge, or machine learning feature selection 
	  techniques.
	4.	Data Integration:
	•	Combine data from multiple sources to enrich the dataset. Ensure alignment 
	  and compatibility between different data sources.
	5.	Feature Engineering:
	•	Create new features that can capture important information in a more useful form. 
	  This might involve aggregating data, creating interaction terms, 
	  or transforming variables.

##  Project Overview
Demand modeling with archival data enables data-driven sales predictions at counterfactual characteristics(prices)
MNL (usually with extensions) is the most popular demand model
  Micro founded
  Well behaved, estimable
  Based on clearly specified theoretical model of choice
Demand parameter estimates may be biased when price is correlated with unobservables that drive demand. This is endogeneity. Can sometimes be dealt with.

Price endogeneity is a major issue in demand estimation: Suppose the data do not record all product attributes that vary and affect demand (eg, brand reputation, coolness, aesthetics, reliability, etc) if unobserved attributes affect both price and quantity, then predictors are correlated with errors, and we say endogeneity would bias demand estimates. This is just like the assumption in linear regression that cov(X,e)=0. in this modeling I am going to disregard endogeneity for simplicity. 
Instead of predict demand people usually see the product's quantity response to a change in price.

## Import Data 
```{r}
#Using T-mobile customer phone data
library(tidyverse)
library(mlogit)
library(readr)
cust_dat <- read_csv("./smartphone_customer_data.csv", show_col_types = F)
n <- nrow(cust_dat)
# replace missing 'discount' values (currently NA) with empty string ("")
cust_dat <- cust_dat |> mutate(discount = ifelse(is.na(discount), "", discount))
set.seed(1357)   
    subk <- cust_dat |> select(gaming, chat, maps, video, social, reading)
    outk <- kmeans(subk, centers = 3, nstart = 10)
    table(outk$cluster)
    cust_dat$segment <- factor(outk$cluster)
    rm(subk, outk)
# import phone attributes     
    phone_dat <- read_csv("./phone_dat.csv", show_col_types = F)
``` 

## Create Dataset for MNL -----

Now we need to combine these datasets.  The customer data has "n" rows and for
each customer, there were 6 phones available on the market when the customer
purchased their phone.  So we will construct a dataset that has n*6 rows. This 
facilitates mlogit calculating a predicted utility for each available option for
each available customer
    
I'm going to do this in three steps.
    
Step 1: loop over customers and create a dataset of the 6 available phones
for that customer. This is a very flexible way to structure the data.  It
will be useful to us because we may need to adjust the price of a phone
if it was on discount, and this adjustment is customer-specific. More
generally, this is a good way to structure data for a MNL model since it would
allow different customers to choose from different sets of products.
    
step 2: we will stack (ie append) these n datasets on top of each other to
create the dataset with the n*6 rows.
    
Step 3: the 'mlogit' package that fits the MNL model requires us to create
an mlogit-data object, so we'll do that, and then we'll feed that mlogit-data
object into the mlogit() function to estimate the parameters of this model.

```{r}
# create an empty list to store the n datasets (each dataset will have 6 rows)
    dat_list <- vector(mode = "list", length = n)
pb <- txtProgressBar(min = 1, max = n, style = 3)

#loop for step 1

    for (i in 1:n) {
      # get cohort, minutes, brand, and size for customer i
      i_cohort   <- cust_dat |> slice(i) |> pull(years_ago)   
      i_brand    <- cust_dat |> slice(i) |> pull(brand)
      i_size     <- cust_dat |> slice(i) |> pull(screen_size)
      i_discount <- cust_dat |> slice(i) |> pull(discount)
      i_segment  <- cust_dat |> slice(i) |> pull(segment)
      i_minutes  <- cust_dat |> slice(i) |> pull(total_minutes)
    
      # subset the phone data to the 6 phones for the year when the customer purchased
      PD <- phone_dat |> filter(years_ago == i_cohort)
    
      # adjust one of the phone's price for the 10% discount, if applicable
      PD <- PD |> mutate(price = price - (phone_id == i_discount) * price * 0.1)
    
      # add customer id to PD
      PD <- PD |> mutate(customer_id = i)
    
      # convert the one brand variable into a set of 3 brand dummies (ie, binary variables)
      PD <- PD |> mutate(
        apple = as.integer(brand == "apple"),
        huawei = as.integer(brand == "huawei"),
        samsung = as.integer(brand == "samsung")
      )
    
      # create a binary variable to indicate the chosen phone
      # this is going to be the dependent variable in the MNL model (like "y" in OLS)
      PD <- PD |>
        mutate(choice = (brand == i_brand) & (screen_size == i_size)) |>
        mutate(choice = as.integer(choice))
    
      # add segment and total_minutes
      PD <- PD |> mutate(segment = i_segment, total_minutes = i_minutes)
    
      # store this 6-row dataset in the i'th position of that list we initialized before the loop
      dat_list[[i]] <- PD |> select(
        customer_id, phone_id, choice,
        apple, huawei, samsung,
        price, screen_size,
        segment, total_minutes
      )
    
    }
    
    # clean up -- delete temporary objects from the loop that we don't need anymore
    rm(i, i_cohort, i_brand, i_size, i_discount, i_segment, i_minutes, PD, pb)
    
    # Let's take a look at two (out of the n) 6-row datasets:
    dat_list[1]
    dat_list[100]
    
```

```{r}

 # Step 2 -----
    
    #Stacking the n 6-row customer-specific dataframes into one big dataframe 
#(that will have n*6 rows)
    
    # rbind operates on dataframes to concatenate rows
    # Using do.call in order to concatenate rows within lists
    mnl_dat <- as_tibble(do.call(rbind, dat_list))
    
    rm(dat_list)
    
    #Data frame should looks like this 
    head(mnl_dat, n = 20)
    
    # Then estimating demand for each year separately, since customer preferences may
#have changed across product generations
    
    # Let's split the big (n*6 row) dataframe into 3 dataframes, one for each year.
    sub1 <- mnl_dat |> filter(customer_id %in% which(cust_dat$years_ago == 1))
    sub2 <- mnl_dat |> filter(customer_id %in% which(cust_dat$years_ago == 2))
    sub3 <- mnl_dat |> filter(customer_id %in% which(cust_dat$years_ago == 3))
  
```

```{r}

# Step 3 -----

    # converting the 3 'sub' dataframes into mlogit.data objects.
    # To do that, need to specify the y variable (choice), whether our datasets
    # have 6 times as many rows as the original data (shape="long") or 6 times as
    # many columns (shape="wide"), and the id variable that groups the set of
    # phones from one choice-occasion together (our "customer_id" variable).
    
    mdat1 <- mlogit.data(sub1, choice = "choice", shape = "long", chid.var = "customer_id")
    mdat2 <- mlogit.data(sub2, choice = "choice", shape = "long", chid.var = "customer_id")
    mdat3 <- mlogit.data(sub3, choice = "choice", shape = "long", chid.var = "customer_id")
    
    

    
    # Then I will use customer that bought phones last year 
    #(ie, sub1 and mdat1 where "years_ago" == 1) as an example.
 
## Calculate market shares ----

    
    # Calculating product-level and brand-level market shares:
    
    brand_shares <- cust_dat |>
                      filter(years_ago == 1) |>
                      count(brand) |>
                      mutate(shr = n / sum(n))
    
    brand_shares
    
    product_shares <- cust_dat |>
                          filter(years_ago == 1) |>
                          count(phone_id) |>
                          mutate(shr = n / sum(n))
    
    product_shares

# Fit basic (brand-intercept only) model -----

    # Always start simple. For the first model, I will fit a model where our "X"
    # variables are just the binary dummy variables that indicate brand.
    # to leave out one phone as a "baseline" and omit an intercept, so that this
    # model is "identified" (ie, can be estimated).Omiting the intercept by
    # including the bar-zero ("|0") in the formula:
    
    out1 <- mlogit(choice ~ apple + samsung | 0, data = mdat1)
    
    summary(out1)
    
    # The coefficients for the Apple and Samsung brand dummies are
    # positive and statistically significantly different from zero. Those are in
    # comparison to the Huawai coefficient which is restricted to zero for identification.
    # But what do those parameters mean?
    
    # Then using these coefficients to calculate the model's estimate of brand-level
    # market shares. 

        # print the coefficients
        coef(out1)
        
        # print the brand market shares estimated from the model
        coefs1 <- c(huawei = 0, coef(out1))
        shares1 <- exp(coefs1) / sum(exp(coefs1)) # 𝑒^Vi/∑_j𝑒^Vj
        round(shares1, 3)
        
        # print the actual brand market shares
        brand_shares
        
        # print the actual product market shares
        product_shares
        
        # clean up
        rm(coefs1, shares1)
        
        
    # The model fits the intercepts in order to **exactly**
    # match the brand-level market shares from the data. However, it does not match
    # the product-level market shares.
    
    # Second, and this is more subtle but general, the sign and magnitude of the
    # coefficients inform of us the impact on estimated market shares: larger positive
    # coefficients predict larger market shares. Apple has the largest coefficient
    # and thus the largest estimated market share.

    # More illustration, calculate two measures of model fit/performance.
    # using custom functions to make the calculations easy to repeat.



# Model Fit Functions -----

    # The first is the "hit rate" which is the percent of choices the model
    # correctly predicts. Creating custom functions for the brand hit rate
    # and the product hit rate. This measure is something that probably
    # commonly encounter in industry according to text book, as it has a straightforward interpretation.
    
    brand_hit_rate <- function(data, model) {
        # here I use the model to predict which phone maximizes each customer's utility
        preds <- apply(predict(model, newdata = data), 1, which.max)
        # here I construct a vector of customer choices for comparisons to predictions
        actuals <- apply(matrix(data$choice, ncol = 6, byrow = T), 1, which.max)
        # here I compare the model's predictions to the data
        mean(ceiling(preds / 2) == ceiling(actuals / 2))
    }
    
    # now do the same steps but at the phone level
    product_hit_rate <- function(data, model) {
        preds <- apply(predict(model, newdata = data), 1, which.max)
        actuals <- apply(matrix(data$choice, ncol = 6, byrow = T), 1, which.max)
        mean(preds == actuals)
    }
    
    # The second measure of model fit is the likelihood ratio index 
    # (also called McFadden's pseudo # R-squared). 
    # Like R^2 from linear regression, this metric ranges from
    # zero to one, and the interpretation is the degree of improvement over the
    # random guessing about consumer choices
    
    ll_ratio <- function(data, model) {
        N <- nrow(model$probabilities)
        J <- ncol(model$probabilities)
        ll0 <- N * log(1 / J)   # this is the null model for comparison
        ll1 <- as.numeric(model$logLik)   # this is lnL(beta) from slides
        1 - ll1 / ll0
    }
    

    
    
    # Then calculating the brand hit rate and the likelihood ratio index for
    # mnl model. 
    brand_hit_rate(mdat1, out1)
    product_hit_rate(mdat1, out1)
    ll_ratio(mdat1, out1)
    
    # The simple/naive "model" is that each brand is chosen 33.3% (=1/3).
    # The brand hit rate is about 35.6%, which is just a bit better than the naive approach.
    # The likelihood ratio index confirms that the model is not much better than random guessing.
    
    # One way can improve a model's performance is to give it more complete data 
    # (ie, more variables). 





# Add Price -----

    # Adding the price variable to the model and see what happens:
    
    out2 <- mlogit(choice ~ apple + samsung + price | 0, data = mdat1)
    
    summary(out2)
```


## Some Observations


Firstly, it is observed that the coefficients for Apple and Samsung have significantly increased. This suggests that, when price is held constant, consumers demonstrate a stronger preference for Apple and Samsung over Huawei. Market share data indicates that Apple and Samsung dominate over Huawei, which can be attributed to both brand loyalty and pricing strategies. Huawei’s devices, often priced lower than those of Apple and Samsung, achieve competitive market shares due in part to a positive brand perception of Apple and Samsung. This is counterbalanced by the negative impact of their higher pricing.

Secondly, the negative coefficient associated with price implies that higher prices result in decreased utility for consumers and, consequently, lower market shares. This relationship is intuitive and aligns with economic principles.

Thirdly, the presence of smaller p-values in the analysis may indicate that the current model provides a better fit to the observed data compared to previous models.


## Testing for the Better Fitting Hypothesis


```{r}
  
    # Let's test that "better fitting" hypothesis by calculating the hit rates and
    # likelihood ratio index for this model.

        brand_hit_rate(mdat1, out2)
        product_hit_rate(mdat1, out2)
        ll_ratio(mdat1, out2)

    # Got a small improvement in brand hit rate which is now 35.6%, compared to
    # the prior model's brand hit rate of 35.5%.
    
    # Got a product hit rate of 24.8%, better than simpler model's product hit rate 
    # of 24.0%
    
    # That improvement is noticeable in the likelihood ratio statistic. .037 is much better
    # than our previous fit of .002
    
    
    # Let's see what has happened to the brands' market share predictions
    # First need to predict phone shares, then sum over phones to predict brand shares

        #predict phone shares
        shares2p <- colMeans(predict(out2, newdata = mdat1))
        names(shares2p) <- sub1 |> head(6) |> pull(phone_id)
        
        #sum over phones to predict brand shares
        shares2b <- colSums(matrix(shares2p, nrow = 2))
        names(shares2b) <- c("apple", "samsung", "huawei")
    
    round(shares2b, 3)
    brand_shares
    
    # ...still exactly match actual brand-level market shares
    
    round(shares2p, 3)
    product_shares
    
    # ...and now I have product-level market share estimates that better reflect
    # the actual product-level market shares, albeit not perfectly.
    # That's probably because I don't have any product-specific attributes or dummies.





# Add Size -----

    # Improve the model further by fitting MNL with brand, price, and size
    
    out3 <- mlogit(choice ~ apple + samsung + price + screen_size | 0, data = mdat1)
    
    summary(out3)
    
    brand_hit_rate(mdat1, out3)
    product_hit_rate(mdat1, out3)
    ll_ratio(mdat1, out3)
```


## Some Observations


  The “size” variable’s coefficient lacks statistical significance, and the hit rates remain virtually the same. This indicates that the “size” variable might not be contributing significantly to the model. The likely reason could be the high correlation between screen size and price, suggesting that the price variable may already account for most of the information provided by the size variable.

Interestingly, the coefficient for price increased from -0.006 to -0.005, implying that screen size has an influence on price that was not captured in the previous model. This could mean that the previous model suffered from endogeneity issues.

Specifically, the original price coefficient of -0.006 was not solely due to price but also incorporated an effect from screen size. After adjusting for screen size, the price coefficient shifted to -0.005.

Recalling our market mapping exercise, Samsung’s large phones, which featured very big screens, had a low market share. This observation suggests that it might be beneficial to estimate intercepts specific to each phone model instead of using a common screen size parameter for all phones.


```{r}

# Use Product-Specific Intercepts -----

    # Now fit the MNL model with product-specific intercepts and price
    
    # Now, instead of brand dummy variables, I will use product dummy variables.
    # So there will be 5 dummies (one phone has to be set to 0 for identification).
    # Notice that because size does not vary for a given phone, so cannot include
    # it in the model because it would be perfectly collinear with the phone dummies.
    
    out4 <- mlogit(choice ~ phone_id + price | 0, data = mdat1)
    
    summary(out4)
    
    # Notice that many of the coefficients are negative. This is because the small
    # Apple phone is the reference product (simply because it's listed first), so
    # all phones with smaller market shares than Apple small have lower parameter estimates
    
    # Notice also that price coefficient has changed yet again to -0.007. Specifically,
    # the screen size variable in the prior model was capturing the average effect
    # of screen size across the 3 brands.  Now, have specified a more flexible model
    # in which screen size and all other product-specific differences are accounted
    # for by the product dummies
    
    # the fit metrics

        brand_hit_rate(mdat1, out4)
        product_hit_rate(mdat1, out4)
        ll_ratio(mdat1, out4)

    # The brand hit rate improved 1% from 35.5% to 36.7%.
    # The product hit rate improved 2% from 24.8% to 26.9%.
    # The improvement comes from the flexibility of the model to allow for different
    # preferences for small and large phones *within* a brand.
    # LL Ratio is now up to .042, 21x larger than the .002 in the brand-only model
    
    # check the brand-level market shares
    
    shares4p <- colMeans(predict(out4, newdata = mdat1))
    names(shares4p) <- sub1 |> head(6) |> pull(phone_id)
    
    shares4b <- colSums(matrix(shares4p, nrow = 2))
    names(shares4b) <- c("apple", "samsung", "huawei")
    
    round(shares4b, 3)
    brand_shares
    
    # still exactly match actual brand-level market shares
    
    round(shares4p, 3)
    product_shares
    
    # and now it's able to exactly match product-level market shares.

```
The next step involves enhancing our model by incorporating customer-specific heterogeneity. While the model currently performs well on an aggregate level, assessing and tailoring it to individual variations will potentially increase its accuracy and relevance for specific customers. This could involve adding parameters or features that capture unique behaviors or preferences of different customer segments
